{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36521e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports, initalize output path as none \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tkinter import Tk, filedialog\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "import shutil\n",
    "output_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "61421f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_directory():# Get the output directory from user input\n",
    "    \"\"\"\n",
    "    This function prompts the user to select an output directory using a graphical file dialog.\n",
    "\n",
    "    Returns:\n",
    "        str: The path of the selected output directory.\n",
    "\n",
    "    Raises:\n",
    "        Exception: If no directory is selected by the user.\n",
    "    \"\"\"\n",
    "    # Initialize the Tkinter root window\n",
    "    root = Tk()\n",
    "\n",
    "    # Lift the root window to the top\n",
    "    root.lift()\n",
    "    root.attributes('-topmost', True)\n",
    "    \n",
    "    # Open a directory selection dialog and store the selected directory\n",
    "    directory = filedialog.askdirectory(title=\"Select Output Directory\", parent=root)\n",
    "\n",
    "    # Withdraw the root window after the dialog is closed\n",
    "    root.withdraw()\n",
    "\n",
    "    # Check if a directory was selected\n",
    "    if directory:\n",
    "        return directory\n",
    "    else:\n",
    "        raise Exception(\"No directory selected.\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96e01020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def screen_data(df, features, wtloss): # data screening function\n",
    "    \"\"\"\n",
    "    Creates a subset of the desired features and applies listwise deletion (deletes rows if any feature is missing).\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): Original DataFrame.\n",
    "        features (list): List of feature column names to retain.\n",
    "        wtloss (str): Column name of the target variable to check correlations with.\n",
    "    \n",
    "    Returns:\n",
    "        subset (DataFrame): Processed DataFrame after listwise deletion.\n",
    "    \"\"\"\n",
    "    subset = df[features + [wtloss]].dropna(axis=0, how='any')\n",
    "    \n",
    "    if subset.empty:\n",
    "        print(f\"Dataset is empty.\")\n",
    "        return None\n",
    "\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a2d91cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def significance_test(df, corr_matrix, target_column, alpha): # test significance of pearson correlation coefficient and return results\n",
    "    \"\"\"\n",
    "    Conducts a standard t-test to check the significance of each Pearson correlation coefficient \n",
    "    with respect to the target column using a specified significance level.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame containing the data.\n",
    "        corr_matrix (DataFrame): Correlation matrix of the data.\n",
    "        target_column (str): Column name of the target variable.\n",
    "        alpha (float): Significance level threshold.\n",
    "        \n",
    "    Returns:\n",
    "        results_df (DataFrame): DataFrame containing coefficients, p-values and significance.\n",
    "    \"\"\"\n",
    "    # print(f\"Standard t-test to check significance of each Pearson correlation coefficient with respect to '{target_column}' using significance level {alpha}\")\n",
    "    \n",
    "    correlations = corr_matrix[target_column]\n",
    "    p_values = []\n",
    "    for column in df.columns:\n",
    "        if column != target_column:\n",
    "            corr_coeff = correlations[column]\n",
    "            df_residuals = len(df) - 2\n",
    "            t_statistic = corr_coeff * np.sqrt(df_residuals) / np.sqrt(1 - corr_coeff ** 2)\n",
    "            p_value = 2 * (1 - stats.t.cdf(np.abs(t_statistic), df_residuals))\n",
    "            p_values.append(p_value)\n",
    "        else:\n",
    "            p_values.append(np.nan)  # not testing the target column against itself\n",
    "\n",
    "    p_values_df = pd.DataFrame(p_values, index=df.columns, columns=['p-value'])\n",
    "    significant = p_values_df['p-value'] < alpha\n",
    "    significant[target_column] = False  # self-correlation set to False\n",
    "            \n",
    "    results_df = pd.DataFrame({\n",
    "        'Correlation Coefficient': correlations,\n",
    "        'Significant': significant\n",
    "    })\n",
    "    # Sort by significance (True first) and then by descending correlation\n",
    "    results_df = results_df.sort_values(by=['Significant', 'Correlation Coefficient'], ascending=[False, False])\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bbbce1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(output_path, saveName, wtloss, corr_mat): # heat map plotting and saving for correlation matrices\n",
    "    \"\"\"\n",
    "    This function plots a heatmap of the correlation matrix for the given weight loss data.\n",
    "\n",
    "    Parameters:\n",
    "        weight_loss_data (str): The dataset or context description for weight loss data.\n",
    "        correlation_matrix (DataFrame): The correlation matrix to be plotted as a heatmap.\n",
    "    \"\"\"\n",
    "    # Set up the matplotlib figure\n",
    "    plt.figure(figsize=(12, 10))\n",
    "\n",
    "    # Create a heatmap using seaborn\n",
    "    sns.heatmap(corr_mat, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True, square=True, linewidths=0.5, annot_kws={\"size\": 10})\n",
    "\n",
    "    # Add title and labels\n",
    "    plt.title(f'Correlation Matrix Heatmap for {wtloss}', fontsize=15)\n",
    "    plt.xticks(rotation=45, ha='right')  # Rotate labels to prevent overlapping\n",
    "    plt.yticks(rotation=45)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    # Save the figure to the specified folder\n",
    "    plt.savefig(os.path.join(output_path, f\"correlation_heatmap_{saveName}.png\"))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1048c7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_excel(output_file, saveName, results_df,corr_mat): # saves a df to a previosly created excel work book\n",
    "    \"\"\"\n",
    "    Save results and correlation matrix to an existing Excel workbook.\n",
    "\n",
    "    Parameters:\n",
    "        output_file (str): The path to the output Excel file.\n",
    "        sheet_name (str): The name of the sheet to write data to.\n",
    "        results_df (pd.DataFrame): The dataframe containing results.\n",
    "        corr_mat (pd.DataFrame): The correlation matrix dataframe.\n",
    "    \"\"\"\n",
    "    # Create a Pandas Excel writer using openpyxl as the engine\n",
    "    with pd.ExcelWriter(output_file, mode='a', engine='openpyxl', if_sheet_exists='replace') as writer:\n",
    "\n",
    "        # Write the results_df to the specified sheet\n",
    "        results_df.to_excel(writer, sheet_name=saveName,startrow=2, index=True)\n",
    "        writer.sheets[saveName].cell(row=1, column=1, value=f\"Pearson correlation coefficients and results of significance test for {saveName}\")    \n",
    "    \n",
    "    with pd.ExcelWriter(output_file, mode='a', engine='openpyxl', if_sheet_exists='overlay') as writer:    \n",
    "        \n",
    "        # Calculate the starting row for the correlation matrix\n",
    "        start_row = results_df.shape[0] + 6  # +2 to add 1 empty row between the two dataframes\n",
    "        writer.sheets[saveName].cell(row=start_row, column=1, value=f\"correlation matrix with respect to screening based on {saveName}\") \n",
    "            \n",
    "        # Write the corr_mat to the same sheet starting from 'start_row'\n",
    "        corr_mat.to_excel(writer, sheet_name=saveName, startrow=start_row+1, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd671e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputResults(output_path, output_file, saveName, results_df, alpha, wtloss, corr_mat):# handle all post process result saving and display \n",
    "    \"\"\"\n",
    "    Handles all post-process result saving and display tasks.\n",
    "\n",
    "    Parameters:\n",
    "        output_path (str): Directory where output files will be saved.\n",
    "        output_file (str): Path to the Excel file where results will be saved.\n",
    "        save_name (str): The name under which to save the results.\n",
    "        results_df (pd.DataFrame): DataFrame containing the results to be output.\n",
    "        alpha (float): Significance level used in the tests.\n",
    "        wtloss (str): The parameter with respect to which the tests are conducted.\n",
    "        corr_mat (pd.DataFrame): Correlation matrix to be saved and visualized.\n",
    "\n",
    "    Returns:\n",
    "        None    \n",
    "    \"\"\"\n",
    "    print(f\"\\nSignificance and Correlation Test Results using alpha =\", alpha, ' with respect to', wtloss, ':\\n', results_df,'\\n')\n",
    "    save_to_excel(output_file, saveName, results_df,corr_mat)\n",
    "    plot_heatmap(output_path,saveName, wtloss, corr_mat)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8727ddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_location_pre_processing(output_path):\n",
    "    \"\"\"\n",
    "    Prepares the output directory and file for correlation significance results.\n",
    "\n",
    "    Parameters:\n",
    "        output_path (str, optional): The base directory where results will be saved. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the output directory path and the output file path.\n",
    "    \"\"\"\n",
    "    # create output path and file \n",
    "    if output_path is None:\n",
    "        output_path = get_output_directory()\n",
    "        output_path = f\"{output_path}/correlation_significance_results\"\n",
    "        output_file = f\"{output_path}/correlation_significance_test_results.xlsx\"\n",
    "\n",
    "  \n",
    "    # Check if the directory exists and replace it \n",
    "    if os.path.exists(output_path):\n",
    "        shutil.rmtree(output_path)\n",
    "        \n",
    "    os.makedirs(output_path)\n",
    "\n",
    "    # Check if the file already exists\n",
    "    if os.path.isfile(output_file):\n",
    "        # Remove the existing file\n",
    "        os.remove(output_file)\n",
    "    return output_path, output_file\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f62c1d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data set loading, feature definitions,alpha for significance test\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel('..\\Project Dataset.xlsx', sheet_name='data', engine='openpyxl')\n",
    "\n",
    "# defining the desired weight loss reporting methods for screening\n",
    "wtlossreporting= [['BOD (% /day)','BOD'], ['wt. loss (% /day)','WT']]\n",
    "         \n",
    "# defining significance level \n",
    "alpha = 0.1\n",
    "\n",
    "# renaming features for clarity\n",
    "df = df.rename(columns={'BOD (% day-1)': 'BOD (% /day)',\n",
    "                        'wt. loss (% day-1)':'wt. loss (% /day)',                        \n",
    "                        'den (g mL-1)':'den (g/mL)',\n",
    "                        \"% cryst\": \"% crystallinity\", \n",
    "                        \"enthalpy (J g-1)\": \"enthalpy (J/g)\", \n",
    "                        \"LogP(SA)-1 (Å-2)\": \"LogP/(SA)\", \n",
    "                        \"Mw (kg mol-1)\": \"Mw (kg/mol)\",\n",
    "                        \"Mn (kg mol-1)\": \"Mn (kg/mol)\",\n",
    "                        })\n",
    "\n",
    "# defining the subset features\n",
    "features = ['den (g/mL)', \n",
    "            'total sp3 C', \n",
    "            '% sp3 C', \n",
    "            'LogP/(SA)',\n",
    "            'Mw (kg/mol)', \n",
    "            'Mn (kg/mol)', \n",
    "            'Mw/Mn',\n",
    "            'Tg (°C)', \n",
    "            'Tm (°C)', \n",
    "            '% crystallinity', \n",
    "            'enthalpy (J/g)', \n",
    "            '(Tw-Tg)/(LogP/SA)'\n",
    "            ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b19aa41d",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "No directory selected.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#handle all data processing \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m output_path, output_file \u001b[38;5;241m=\u001b[39m \u001b[43msave_location_pre_processing\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Create a new workbook\u001b[39;00m\n\u001b[0;32m      5\u001b[0m wb \u001b[38;5;241m=\u001b[39m openpyxl\u001b[38;5;241m.\u001b[39mWorkbook()\n",
      "Cell \u001b[1;32mIn[44], line 13\u001b[0m, in \u001b[0;36msave_location_pre_processing\u001b[1;34m(output_path)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# create output path and file \u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 13\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m \u001b[43mget_output_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/correlation_significance_results\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     15\u001b[0m     output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/correlation_significance_test_results.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[38], line 28\u001b[0m, in \u001b[0;36mget_output_directory\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m directory\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 28\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo directory selected.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: No directory selected."
     ]
    }
   ],
   "source": [
    "#handle all data processing \n",
    "output_path, output_file = save_location_pre_processing(output_path)\n",
    "\n",
    "# Create a new workbook\n",
    "wb = openpyxl.Workbook()\n",
    "# Save the workbook to the specified file\n",
    "wb.save(output_file)   \n",
    "\n",
    "for [wtloss, saveName] in wtlossreporting:   \n",
    "    \n",
    "    print(\"Conducting analysis with respect to:\", wtloss) \n",
    "        \n",
    "    data = screen_data(df, features, wtloss)\n",
    "        \n",
    "    if data is not None:\n",
    "        corr_mat = data.corr()\n",
    "        print(f\"Subset size: {data.shape}\")\n",
    "        results_df = significance_test(data, corr_mat, wtloss, alpha)\n",
    "        outputResults(output_path, output_file, saveName, results_df, alpha, wtloss, corr_mat)\n",
    "    else:\n",
    "        print(\"Encountered unhandled error for {wtloss} analysis\")\n",
    "\n",
    "\n",
    "# Load the workbook\n",
    "wb = load_workbook(output_file)\n",
    "\n",
    "# Remove the first sheet\n",
    "wb.remove(wb[wb.sheetnames[0]])\n",
    "\n",
    "# Save the workbook to apply changes\n",
    "wb.save(output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
