{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "962d3095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from imblearn.over_sampling import SMOTE  # For oversampling the minority class\n",
    "from tkinter import Tk, filedialog\n",
    "from sklearn.base import BaseEstimator\n",
    "from matplotlib.colors import ListedColormap\n",
    "import shutil\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "import tkinter as tk\n",
    "\n",
    "# Initialize output path as None\n",
    "output_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ea3842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def screen_data(df, features, target): # data screening function\n",
    "    \"\"\"\n",
    "    Creates a subset of the desired features and applies listwise deletion (deletes rows if any feature is missing).\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): Original DataFrame.\n",
    "        features (list): List of feature column names to retain.\n",
    "        target (str): optional one off parameter.\n",
    "    \n",
    "    Returns:\n",
    "        subset (DataFrame): Processed DataFrame after listwise deletion.\n",
    "    \"\"\"\n",
    "    if target is not None:\n",
    "        subset = df[features + [target]].dropna(axis=0, how='any')\n",
    "    else:\n",
    "        subset = df[features].dropna(axis=0, how='any')\n",
    "        \n",
    "    \n",
    "    if subset.empty:\n",
    "        print(f\"Dataset is empty.\")\n",
    "        return None,\n",
    "\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e783241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_output_directory():# Get the output directory from user input\n",
    "    \"\"\"\n",
    "    This function prompts the user to select an output directory using a graphical file dialog.\n",
    "\n",
    "    Returns:\n",
    "        str: The path of the selected output directory.\n",
    "\n",
    "    Raises:\n",
    "        Exception: If no directory is selected by the user.\n",
    "    \"\"\"\n",
    "    # Initialize the Tkinter root window\n",
    "    root = Tk()\n",
    "\n",
    "    # Lift the root window to the top\n",
    "    root.lift()\n",
    "    root.attributes('-topmost', True)\n",
    "    \n",
    "    # Open a directory selection dialog and store the selected directory\n",
    "    directory = filedialog.askdirectory(title=\"Select Output Directory\", parent=root)\n",
    "\n",
    "    # Withdraw the root window after the dialog is closed\n",
    "    root.withdraw()\n",
    "\n",
    "    # Check if a directory was selected\n",
    "    if directory:\n",
    "        return directory\n",
    "    else:\n",
    "        raise Exception(\"No directory selected.\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b6b734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_location_pre_processing(output_path, kernel):\n",
    "    \"\"\"\n",
    "    Prepares the directory and file path for saving SVM classification reports.\n",
    "    \n",
    "    Parameters:\n",
    "    output_path (str): The desired output directory path. If None, the user will be prompted to select one.\n",
    "    kernel (str): The kernel type used for the SVM.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: A tuple containing the output directory path and the full file path for excel classification reports.\n",
    "    \"\"\"\n",
    "    \n",
    "    folder_name = f\"SVM_{kernel}_results\"\n",
    "    file_name = f\"SVM_{kernel}_classification_report.xlsx\"\n",
    "\n",
    "    # If no output path is provided, prompt the user to select a directory\n",
    "    if output_path is None:\n",
    "        output_path = select_output_directory()\n",
    "        \n",
    "    output_directory = os.path.join(output_path, folder_name)\n",
    "    output_file = os.path.join(output_directory, file_name)\n",
    "  \n",
    "    # Delete the directory if it already exists \n",
    "    if os.path.exists(output_directory):\n",
    "        shutil.rmtree(output_directory)\n",
    "        \n",
    "    # Check if the file already exists, and remove if it does\n",
    "    if os.path.isfile(output_file):\n",
    "        os.remove(output_file)\n",
    "    \n",
    "    return output_directory, output_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef2ab1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_excel(output_file, sheet_name, results_df, description):\n",
    "    \"\"\"\n",
    "    Saves a DataFrame to an existing Excel workbook, with the ability to add a description.\n",
    "    \n",
    "    Parameters:\n",
    "    output_file (str): The path to the Excel file where the DataFrame will be saved.\n",
    "    sheet_name (str): The name of the sheet where the DataFrame will be written.\n",
    "    results_df (pd.DataFrame): The DataFrame containing results to be saved.\n",
    "    description (str): A description to be placed at the beginning of the sheet.\n",
    "    \"\"\"\n",
    "\n",
    "    # Use Pandas Excel writer with Openpyxl as the engine\n",
    "    with pd.ExcelWriter(output_file, mode='a', engine='openpyxl', if_sheet_exists='replace') as writer:\n",
    "        # Write the DataFrame to the specified sheet, starting at row 2\n",
    "        results_df.to_excel(writer, sheet_name=sheet_name, startrow=2, index=True)\n",
    "        \n",
    "        # Write the description in the first cell of the sheet\n",
    "        worksheet = writer.sheets[sheet_name]\n",
    "        worksheet.cell(row=1, column=1, value=description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c78eb32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_marker_map(subset, target):\n",
    "    \"\"\"\n",
    "    Generates a mapping from unique '3-tier rank' values to specific marker symbols.\n",
    "\n",
    "    Parameters:\n",
    "    subset (pandas.DataFrame): The data subset containing the '3-tier rank' values.\n",
    "    target (str): The column name in 'subset' which contains the '3-tier rank' values.\n",
    "\n",
    "    Returns:\n",
    "    tuple:\n",
    "        - marker_map (dict): A dictionary mapping each unique '3-tier rank' value to a marker symbol.\n",
    "        - unique_rates (List of strings): A list of the sorted unique '3-tier rank' values.\n",
    "\n",
    "    Raises:\n",
    "    AssertionError: If the number of unique '3-tier rank' values is not exactly three. \n",
    "    \n",
    "    Note: could modify this by adding more markers so the same tests can be done for the 5 tier rank\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve and sort the unique '3-tier rank' values from the target column\n",
    "    unique_rates = subset[target].unique()\n",
    "    unique_rates.sort()\n",
    "\n",
    "    # Ensure there are exactly three unique '3-tier rank' values\n",
    "    assert len(unique_rates) == 3, \"The dataset must have exactly 3 unique '3-tier rank' values\"\n",
    "\n",
    "    # Define a list of distinct markers corresponding to the three unique '3-tier rank' values\n",
    "    markers = ['^', 'o', 's']\n",
    "    marker_map = {rate: markers[i] for i, rate in enumerate(unique_rates)}\n",
    "\n",
    "    return marker_map, unique_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5274ea05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(df_train, df_test, target, feature_x, \n",
    "                            feature_y, marker_map, rates, labels, kernel_choice,\n",
    "                            model, train_accuracy, test_accuracy, \n",
    "                            best_param, plot_save_name):\n",
    "\n",
    "    # Define boundaries for the plot\n",
    "    x_min, x_max = np.min([df_train[feature_x].min(), df_test[feature_x].min()]) - 1, np.max([df_train[feature_x].max(), df_test[feature_x].max()]) + 1\n",
    "    y_min, y_max = np.min([df_train[feature_y].min(), df_test[feature_y].min()]) - 1, np.max([df_train[feature_y].max(), df_test[feature_y].max()]) + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "    # Predict on grid points\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    # Z = label_encoder.inverse_transform(Z)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "  \n",
    "    # Create a color map using a sequential or diverging colormap\n",
    "    colors = plt.cm.coolwarm(np.linspace(0, 1, len(rates)))\n",
    "    cmap = ListedColormap(colors)\n",
    "  \n",
    "    # Set up the plots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    # Plot the decision boundaries on both subplots    \n",
    "    contour1 = axes[0].contourf(xx, yy, Z,levels = 3, alpha=0.5, cmap=cmap) \n",
    "    contour2 = axes[1].contourf(xx, yy, Z,levels = 3, alpha=0.5, cmap=cmap)\n",
    "    \n",
    "\n",
    "    # Plot the training and test data with different markers for each class\n",
    "    for i, rate in enumerate(rates):\n",
    "        train_mask = df_train[target] == rate\n",
    "        test_mask = df_test[target] == rate\n",
    "        axes[0].scatter(df_train[feature_x][train_mask], df_train[feature_y][train_mask], \n",
    "                        marker=marker_map[rate], color=colors[i], edgecolors='k', label=labels[i], alpha=0.7)\n",
    "        axes[1].scatter(df_test[feature_x][test_mask], df_test[feature_y][test_mask], \n",
    "                        marker=marker_map[rate], color=colors[i], edgecolors='k', label=labels[i], alpha=0.7)\n",
    "        # decision boundary and prediction check \n",
    "        # pred_mask = df_test[\"prediction\"] == rate\n",
    "        # axes[0].scatter(df_test[feature_x][pred_mask], df_test[feature_y][pred_mask], \n",
    "        #                 marker=marker_map[rate], color=colors[i], edgecolors='k', label=labels[i], alpha=0.7)\n",
    "\n",
    "    if kernel_choice == 'poly':     \n",
    "        main_title = f\"Decision Boundary and Ground Truth: {feature_x} vs {feature_y}\\nKernel: Degree {best_param} polynomial\\nNote: features are standardized\"\n",
    "        fig.suptitle(main_title)\n",
    "        axes[0].set_title(f\"Training Set\\nAccuracy: {train_accuracy:.2f}\")\n",
    "        axes[0].set_xlabel(feature_x)\n",
    "        axes[0].set_ylabel(feature_y)\n",
    "        axes[0].legend(title=target, labels = rates)\n",
    "        \n",
    "        axes[1].set_title(f\"Testing Set\\nAccuracy: {test_accuracy:.2f}\")\n",
    "        axes[1].set_xlabel(feature_x)\n",
    "        axes[1].set_ylabel(feature_y)\n",
    "        axes[1].legend(title=target, labels = rates)\n",
    "    else:\n",
    "        \n",
    "        main_title = f\"Decision Boundary and Ground Truth: {feature_x} vs {feature_y}\\nKernel: {kernel_choice} with regularization hyper-parameter C: {best_param}\\nNote: features are standardized\"\n",
    "        fig.suptitle(main_title)\n",
    "        axes[0].set_title(f\"Training Set\\nAccuracy: {train_accuracy:.2f}\")\n",
    "        axes[0].set_xlabel(feature_x)\n",
    "        axes[0].set_ylabel(feature_y)\n",
    "        axes[0].legend(title=target, labels = rates)\n",
    "        \n",
    "        axes[1].set_title(f\"Testing Set\\nAccuracy: {test_accuracy:.2f}\")\n",
    "        axes[1].set_xlabel(feature_x)\n",
    "        axes[1].set_ylabel(feature_y)\n",
    "        axes[1].legend(title=target, labels = rates)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(plot_save_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "995766b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_feature_pairs(df, features, target, kernel_choice, output_path, output_file, save_name_mapping, param_grid, n_splits=3):\n",
    "    \"\"\"\n",
    "    Evaluates all unique pairs of features using Support Vector Machine (SVM) with specified kernel and hyperparameters.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The DataFrame containing the data.\n",
    "    features (list of str): List of feature column names to be evaluated in pairs.\n",
    "    target (str): The target column name containing '3-tier rank' values.\n",
    "    kernel_choice (str): The choice of kernel for SVM ('linear', 'rbf', etc.).\n",
    "    output_path (str): Directory path to save the plots.\n",
    "    output_file (str): File path to save the Excel outputs.\n",
    "    save_name_mapping (dict): Mapping from feature names to desired save names for files.\n",
    "    n_splits (int): Number of splits for k-fold cross-validation (default is 3).\n",
    "    param_grid (dict): Dictionary specifying the hyperparameters for GridSearchCV (default includes 'C' with values [0.1, 1, 10]).\n",
    "    \n",
    "    Returns:\n",
    "    list: A list containing tuples with feature pairs and their evaluation metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Get marker mapping and labels\n",
    "    marker_map, rates = get_marker_map(df, target)\n",
    "   \n",
    "    # Encode rates to integer labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    labels = label_encoder.fit_transform(rates)\n",
    "    \n",
    "    # Transform the target values from strings to int using label encoder  \n",
    "    y = label_encoder.transform(df[target].values)\n",
    "\n",
    "    # Handle class imbalance using SMOTE\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(df[features].values, y)\n",
    "\n",
    "    # Standardize features for SVM\n",
    "    scaler = StandardScaler()\n",
    "    X_resampled = scaler.fit_transform(X_resampled)\n",
    "    \n",
    "    # Set up k-fold cross-validation\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(len(features)):\n",
    "        for j in range(i + 1, len(features)):\n",
    "            feature_x = features[i]\n",
    "            feature_y = features[j]\n",
    "            \n",
    "            # Extract feature pairs\n",
    "            X_train_features = X_train[:, [i, j]]\n",
    "            X_test_features = X_test[:, [i, j]]\n",
    "            \n",
    "            # Create save names\n",
    "            save_name_x = save_name_mapping[feature_x]\n",
    "            save_name_y = save_name_mapping[feature_y]\n",
    "            plot_save_name = os.path.join(output_path, f\"SVM_{kernel_choice}_plot_{save_name_x}_vs_{save_name_y}.png\")\n",
    "            sheet_name = f\"{save_name_x} and {save_name_y}\"\n",
    "    \n",
    "        \n",
    "            # Process ground truth for plotting using resampled and standardized data\n",
    "            # Prepare the training data\n",
    "            y_train_rates = label_encoder.inverse_transform(y_train)\n",
    "            df_train = pd.DataFrame(X_train_features, columns=[feature_x, feature_y])\n",
    "            df_train[target] = y_train_rates\n",
    "            df_train[\"encoded rates\"] = y_train\n",
    "            \n",
    "            # Prepare the testing data\n",
    "            y_test_rates = label_encoder.inverse_transform(y_test)\n",
    "            df_test = pd.DataFrame(X_test_features, columns=[feature_x, feature_y])\n",
    "            df_test[target] = y_test_rates\n",
    "            df_test[\"encoded rates\"] = y_test\n",
    "            \n",
    "                        \n",
    "            # Initialize the SVM model\n",
    "            if kernel_choice == \"poly\":\n",
    "                svc = SVC(kernel='poly', gamma='scale')\n",
    "                grid_search = GridSearchCV(svc, param_grid, cv=kf)\n",
    "                \n",
    "            elif kernel_choice == 'rbf':\n",
    "                svc = SVC(kernel=kernel_choice, gamma='scale')\n",
    "                # Use GridSearchCV with k-fold cross-validation\n",
    "                grid_search = GridSearchCV(svc, param_grid, cv=kf)\n",
    "            else:\n",
    "                svc = SVC(kernel=kernel_choice)\n",
    "                grid_search = GridSearchCV(svc, param_grid, cv=kf)\n",
    "            \n",
    "            # Use GridSearchCV with k-fold cross-validation\n",
    "            grid_search.fit(X_train_features, y_train)\n",
    "            \n",
    "            # Retrieve the best model and its scores\n",
    "            best_model = grid_search.best_estimator_\n",
    "            best_params = grid_search.best_params_\n",
    "            \n",
    "            # Calculate training and test accuracy\n",
    "            train_accuracy = best_model.score(X_train_features, y_train)\n",
    "            test_accuracy = best_model.score(X_test_features, y_test)\n",
    "                        \n",
    "            # Predict the degradation rate using the test data and best model\n",
    "            y_test_pred = best_model.predict(X_test_features)\n",
    "            y_test_pred_rates = label_encoder.inverse_transform(y_test_pred)\n",
    "            df_test[\"prediction\"] = y_test_pred_rates\n",
    "            \n",
    "            if kernel_choice == \"poly\":\n",
    "                # Save results\n",
    "                results.append((feature_x, feature_y, train_accuracy, test_accuracy, grid_search.best_score_, best_model, best_params['degree']))\n",
    "\n",
    "                # Description for excel sheet\n",
    "                description = (f\"Best model report for SVM model with {kernel_choice} kernel using degree = {best_params['degree']}, and using features: {feature_x} and \"\n",
    "                            f\"{feature_y}\")\n",
    "                            \n",
    "                # Print results\n",
    "                print(f\"SVM Model: {feature_x} vs {feature_y} with {kernel_choice} kernel\")\n",
    "                print(f\"Best degree model: {best_params['degree']}\")\n",
    "                print(f\"Training Accuracy: {train_accuracy:.2f}\")\n",
    "                print(f\"Testing Accuracy: {test_accuracy:.2f}\")\n",
    "                print(\"\\nClassification Report (Test Data):\")\n",
    "                print(classification_report(y_test, y_test_pred, target_names=label_encoder.classes_, zero_division=0))\n",
    "                # Plot decision boundary\n",
    "                plot_decision_boundary(df_train, df_test, target, feature_x, feature_y, marker_map, rates, labels, \n",
    "                                kernel_choice, best_model, train_accuracy, test_accuracy, best_params['degree'], plot_save_name)\n",
    "            else:\n",
    "                # Save results\n",
    "                results.append((feature_x, feature_y, train_accuracy, test_accuracy, grid_search.best_score_, best_model, best_params['C']))\n",
    "            \n",
    "                # Description for excel sheet\n",
    "                description = (f\"Best model report for SVM model with {kernel_choice} kernel using features: {feature_x} and \"\n",
    "                            f\"{feature_y} with C hyperparameter = {best_params['C']}\")\n",
    "                \n",
    "                # Print results\n",
    "                print(f\"SVM Model: {feature_x} vs {feature_y} with {kernel_choice} kernel\")\n",
    "                print(f\"Best C hyperparameter: {best_params['C']}\")\n",
    "                print(f\"Training Accuracy: {train_accuracy:.2f}\")\n",
    "                print(f\"Testing Accuracy: {test_accuracy:.2f}\")\n",
    "                print(\"\\nClassification Report (Test Data):\")\n",
    "                print(classification_report(y_test, y_test_pred, target_names=label_encoder.classes_, zero_division=0))       \n",
    "                    \n",
    "                   \n",
    "                \n",
    "                # Plot decision boundary\n",
    "                plot_decision_boundary(df_train, df_test, target, feature_x, feature_y, marker_map, rates, labels, \n",
    "                                kernel_choice, best_model, train_accuracy, test_accuracy, best_params['C'], plot_save_name)\n",
    "                \n",
    "            # Convert the classification report dictionary to a pandas DataFrame for saving to Excel\n",
    "            report = classification_report(y_test, y_test_pred, target_names=label_encoder.classes_, zero_division=0, output_dict=True)\n",
    "            report.update({\"accuracy\": {\"precision\": None, \"recall\": None, \"f1-score\": report[\"accuracy\"], \"support\": report['macro avg']['support']}})\n",
    "            report_df = pd.DataFrame(report).transpose()\n",
    "            report_df = report_df.round(2)\n",
    "        \n",
    "            # save results in excel\n",
    "            save_to_excel(output_file, sheet_name, report_df, description)\n",
    "                \n",
    "                \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2987cce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data set loading, feature definitions,alpha for significance test\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel('..\\Project Dataset.xlsx', sheet_name='data', engine='openpyxl')\n",
    "\n",
    "# defining the desired weight loss reporting methods for screening\n",
    "wtlossreporting= [['BOD (% /day)','BOD'], ['wt. loss (% /day)','WT LOSS']]\n",
    "         \n",
    "# defining significance level \n",
    "alpha = 0.1\n",
    "\n",
    "# renaming features for clarity\n",
    "df = df.rename(columns={'BOD (% day-1)': 'BOD (% /day)',\n",
    "                        'wt. loss (% day-1)':'wt. loss (% /day)',                        \n",
    "                        'den (g mL-1)':'den (g/mL)',\n",
    "                        \"% cryst\": \"% crystallinity\", \n",
    "                        \"enthalpy (J g-1)\": \"enthalpy (J/g)\", \n",
    "                        \"LogP(SA)-1 (Å-2)\": \"LogP/(SA)\", \n",
    "                        \"Mw (kg mol-1)\": \"Mw (kg/mol)\",\n",
    "                        \"Mn (kg mol-1)\": \"Mn (kg/mol)\",\n",
    "                        '3-tier rank': 'Degradation Rate'\n",
    "                        })\n",
    "\n",
    "# grouping feature for plots\n",
    "target = 'Degradation Rate'\n",
    "\n",
    "# Select the features and target\n",
    "features = [\"% crystallinity\", \n",
    "            \"enthalpy (J/g)\", \n",
    "            \"Tg (°C)\", \n",
    "            \"LogP/(SA)\", \n",
    "            \"Mw (kg/mol)\"\n",
    "            ]\n",
    "\n",
    "target = 'Degradation Rate'\n",
    "\n",
    "# cant use special characters in the save files so now it maps to an acceptable name\n",
    "save_name_mapping = {'den (g/mL)':'density',\n",
    "                    'total sp3 C':'total sp3 C', \n",
    "                    '% sp3 C':'percent sp3 C', \n",
    "                    'LogP/(SA)': 'LogPSA',\n",
    "                    'Mw (kg/mol)': 'MW', \n",
    "                    'Mn (kg/mol)': 'Mn', \n",
    "                    'Mw/Mn':'Ratio MwMn',\n",
    "                    'Tg (°C)':'Tg',\n",
    "                    'Tm (°C)':'Tm',\n",
    "                    '% crystallinity':'percent cryst',\n",
    "                    'enthalpy (J/g)':'enthalpy',\n",
    "                    '(Tw-Tg)/(LogP/SA)':'TWTW_LogPSA'\n",
    "                    }\n",
    "# C hyperparameters tested \n",
    "C = {'C': [0.1, 1, 5, 10, 20, 50, 75, 100, 200, 500]}\n",
    "# Degree hyperparameters tested \n",
    "degree = {'degree': [2,3,4,3,5,6,7,8]}\n",
    "\n",
    "# select kernel to use for SVM\n",
    "kernel = \"poly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b953dfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Note that the data preprocessing includes standard scaling and resampling.(standardScaler() and SMOTE fit_transform())\")\n",
    "\n",
    "# Get output path from user input and pre process the directory\n",
    "output_path, output_file = save_location_pre_processing(output_path, kernel)\n",
    "\n",
    "# create an output folder \n",
    "os.makedirs(output_path)\n",
    "# Create a new workbook\n",
    "wb = openpyxl.Workbook()\n",
    "# Save the workbook to the specified file\n",
    "wb.save(output_file)   \n",
    "\n",
    "\n",
    "# Perform data screening\n",
    "data = screen_data(df, features, target)\n",
    "\n",
    "# Evaluate feature pairs and visualize\n",
    "if kernel == \"poly\":\n",
    "    results = evaluate_feature_pairs(data, features, target, kernel, output_path, output_file, save_name_mapping, param_grid = degree)\n",
    "    # Display results\n",
    "    print(\"Summary Evaluation Results:\")\n",
    "    print(\"Degree tested: \\n \", degree )\n",
    "    print(\"=\" * 40)\n",
    "    for feature_x, feature_y, train_acc, test_acc, best_score, best_model, best_degree in results:\n",
    "        print(f\"Features: {feature_x} vs {feature_y}\")\n",
    "        print(f\"Best C: {best_degree:.2f}\")\n",
    "        print(f\"Training Accuracy: {train_acc:.2f}\")\n",
    "        print(f\"Testing Accuracy: {test_acc:.2f}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "else:\n",
    "    results = evaluate_feature_pairs(data, features, target, kernel, output_path, output_file, save_name_mapping, param_grid = C)\n",
    "    # Display results\n",
    "    print(\"Summary Evaluation Results:\")\n",
    "    print(\"C hyperparameters tested: \\n \", C )\n",
    "    print(\"=\" * 40)\n",
    "    for feature_x, feature_y, train_acc, test_acc, best_score, best_model, best_C in results:\n",
    "        print(f\"Features: {feature_x} vs {feature_y}\")\n",
    "        print(f\"Best C: {best_C:.2f}\")\n",
    "        print(f\"Training Accuracy: {train_acc:.2f}\")\n",
    "        print(f\"Testing Accuracy: {test_acc:.2f}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# Post processing workbook\n",
    "# Load the workbook\n",
    "wb = load_workbook(output_file)\n",
    "# Remove the first sheet\n",
    "wb.remove(wb[wb.sheetnames[0]])\n",
    "# Save the workbook to apply changes\n",
    "wb.save(output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
